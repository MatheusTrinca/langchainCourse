{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9736de",
   "metadata": {},
   "source": [
    "### TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23613c77",
   "metadata": {},
   "source": [
    "Cannot validate data, but its faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1cf933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Inception', 'release_year': 2010, 'genres': ['Action', 'Adventure', 'Sci-Fi'], 'rating': 8.8, 'box_office': 829895144}\n",
      "<class 'dict'>\n",
      "Inception\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Optional, TypedDict, Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.6)\n",
    "\n",
    "class Movie(TypedDict):\n",
    "    title: Annotated[str, \"The title of the movie\"]\n",
    "    release_year: Annotated[int, \"The release year of the movie\"]\n",
    "    genres: Annotated[List[str], \"The genres of the movie belongs to\"]\n",
    "    rating: Annotated[float, \"The rating of the movie\"]\n",
    "    box_office: Annotated[Optional[float], \"The box office of the movie\"]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Movie)\n",
    "\n",
    "result = structured_llm.invoke(\"give me details of movie named Inception\")\n",
    "\n",
    "print(result)\n",
    "print(type(result))\n",
    "print(result[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e571a",
   "metadata": {},
   "source": [
    "### Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cb0e5",
   "metadata": {},
   "source": [
    "Can validate data in run time (Industry standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91d7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Inception' release_year='2010' genres=['Action', 'Sci-Fi', 'Thriller'] rating=8.8 box_office=836836967.0\n",
      "Inception\n",
      "<class '__main__.Movie'>\n",
      "{'title': 'Inception', 'release_year': '2010', 'genres': ['Action', 'Sci-Fi', 'Thriller'], 'rating': 8.8, 'box_office': 836836967.0}\n",
      "{\"title\":\"Inception\",\"release_year\":\"2010\",\"genres\":[\"Action\",\"Sci-Fi\",\"Thriller\"],\"rating\":8.8,\"box_office\":836836967.0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.6)\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    release_year: str = Field(..., description=\"The release year of the movie\")\n",
    "    genres: List[str] = Field(..., description=\"The genres of the movie belongs to\")\n",
    "    rating: float = Field(..., description=\"The rating of the movie\")\n",
    "    box_office: Optional[float] = Field(..., description=\"The box office of the movie\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Movie)\n",
    "\n",
    "result = structured_llm.invoke(\"Give me details of movie named Inception\")\n",
    "\n",
    "print(result)   \n",
    "print(result.title)\n",
    "print(type(result)) # in Pydantic thi is a instance of Movie\n",
    "print(result.model_dump()) # Generates a dictionary from class\n",
    "print(result.model_dump_json()) # Generates a json from class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2a66",
   "metadata": {},
   "source": [
    "### Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ad230b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      4\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.6)\n",
    "\n",
    "\n",
    "movie_json_schema = {\n",
    "    \"name\": \"movie_schema\",\n",
    "    \"description\": \"A movie schema for extracting movie details\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The title of the movie\"\n",
    "            },\n",
    "            \"release_year\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The release year of the movie\"\n",
    "            },\n",
    "            \"genres\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"description\": \"The genres of the movie belongs to\"\n",
    "            },\n",
    "            \"rating\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The rating of the movie\"\n",
    "            },\n",
    "            \"box_office\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The box office of the movie\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"title\", \"release_year\", \"genres\", \"rating\", \"box_office\"],\n",
    "}\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(movie_json_schema)\n",
    "\n",
    "result = structured_llm.invoke(\"Give me details of movie named Inception\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d14ece",
   "metadata": {},
   "source": [
    "#### Product review case (Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1def3207",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      6\u001b[39m load_dotenv()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mProductReview\u001b[39;00m(BaseModel):\n\u001b[32m     11\u001b[39m     product_name: \u001b[38;5;28mstr\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mName of the product being reviewed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\felip\\dev\\langchainCourse\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\felip\\dev\\langchainCourse\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:964\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    954\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    955\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    956\u001b[39m         )\n\u001b[32m    957\u001b[39m     async_specific = {\n\u001b[32m    958\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    959\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    962\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    963\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    968\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\felip\\dev\\langchainCourse\\venv\\Lib\\site-packages\\openai\\_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.6)\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    product_name: str = Field(..., description=\"Name of the product being reviewed\")\n",
    "    reviewer_name: str = Field(..., description=\"Name of the reviewer\")\n",
    "    rating: float = Field(..., description=\"The rating of the product on a scale of 1 to 5\")\n",
    "    pros: List[str] = Field(..., description=\"List of positive aspects of the product\")\n",
    "    cons: List[str] = Field(..., description=\"List of negative aspects of the product\")\n",
    "    review_text: str = Field(..., description=\"Detailed review of the product\")\n",
    "    would_recommend: bool = Field(..., description=\"Whether the reviewer would recommend the product\")\n",
    "    purchase_date: Optional[str] = Field(None, description=\"Date of purchase of the product\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(ProductReview)\n",
    "\n",
    "result = structured_llm.invoke(\"\"\"\n",
    "I purchased these Sony WH-1000XM5 headphones approximately two months ago and I can say without\n",
    "hesitation that it was one of the best tech acquisitions I've ever made. As someone who works\n",
    "remotely and travels frequently, audio quality and noise cancellation are absolutely essential\n",
    "in my daily life.\n",
    "\n",
    "The active noise cancellation is simply exceptional. I tested it in various environments - airplanes,\n",
    "busy coffee shops, noisy offices - and the results always impress. It manages to block out practically\n",
    "all ambient noise, allowing total immersion in music or concentration at work. The transparency mode\n",
    "also works perfectly when I need to hear announcements or talk to someone without removing the headphones.\n",
    "\n",
    "The audio quality is premium. The bass is deep without being excessive, the mids are clear, and the\n",
    "highs are crisp. I tested them with various music genres - from classical music to heavy rock - and\n",
    "the reproduction is always faithful and balanced. For video calls, the microphones capture my voice\n",
    "with impressive clarity.\n",
    "\n",
    "Comfort is another very high point. The cushions are soft and don't squeeze even after 6-8 hours of\n",
    "continuous use. The headband adjusts perfectly to the head without causing discomfort. The battery\n",
    "easily lasts 30 hours with ANC activated, exactly as promised.\n",
    "\n",
    "The negative points are minimal: the price is steep (I paid $450), it's not foldable like the previous\n",
    "model, and occasionally the touch sensor activates accidentally. The case could be more compact.\n",
    "\n",
    "Overall, for those seeking the best in audio quality and noise cancellation, it's worth every penny.\n",
    "I strongly recommend it, especially for demanding professionals and audiophiles.\n",
    "\"\"\")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
